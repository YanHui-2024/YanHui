{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate with FuzzGPT's few-shot (baseline)\n",
    "\n",
    "Randomly select samples from the groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = \"llm_generate\"\n",
    "prompt_path = os.path.join(base_path, \"llm_prompt\")\n",
    "output_path = os.path.join(base_path, \"llm_output\")\n",
    "\n",
    "all_samples = []\n",
    "for category in [\"gpu\", \"operator\", \"syntax\", \"typing\"]:\n",
    "    for sample in os.listdir(os.path.join(base_path, category)):\n",
    "        if not sample.endswith(\".txt\"):\n",
    "            continue\n",
    "        all_samples.append(os.path.join(category, sample))\n",
    "print(len(all_samples))\n",
    "\n",
    "test_index = 0\n",
    "\n",
    "while len(all_samples) > 0:\n",
    "    sample1 = all_samples.pop(random.randrange(len(all_samples)))\n",
    "    sample2 = all_samples.pop(random.randrange(len(all_samples)))\n",
    "    sample3 = all_samples.pop(random.randrange(len(all_samples)))\n",
    "    sample4 = all_samples.pop(random.randrange(len(all_samples)))\n",
    "    samples = [sample1, sample2, sample3, sample4]\n",
    "    print(samples)\n",
    "\n",
    "    prompt_file = os.path.join(prompt_path, f\"test_{test_index}.txt\")\n",
    "    with open(prompt_file, \"w\") as f:\n",
    "        for sample in samples:\n",
    "            sample_file = os.path.join(base_path, sample)\n",
    "            with open(sample_file, \"r\") as f1:\n",
    "                snippet = f1.read()\n",
    "            f.write(f\"{snippet}\\n\\n\")\n",
    "\n",
    "        f.write(\"# API:\")\n",
    "\n",
    "    out_file = os.path.join(output_path, f\"test_{test_index}.txt\")\n",
    "    result = subprocess.run(\n",
    "        [\n",
    "            \"llama-cli\",\n",
    "            \"-m\",\n",
    "            \"/path/to/model\",\n",
    "            \"-c\",\n",
    "            \"16000\",\n",
    "            \"-n\",\n",
    "            \"4096\",\n",
    "            \"-ngl\",\n",
    "            \"1\",\n",
    "            \"-f\",\n",
    "            prompt_file,\n",
    "        ],\n",
    "        check=True,\n",
    "        capture_output=True,\n",
    "    )\n",
    "\n",
    "    with open(os.path.join(output_path, out_file), \"w\") as f:\n",
    "        f.write(\"# API:\")\n",
    "        f.write(result.stdout.decode(\"utf-8\"))\n",
    "\n",
    "    test_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RQ1 evaluation\n",
    "\n",
    "Run each generate test cases and collect the outputs in the `evaluation` directory.\n",
    "\n",
    "Count and compare the valid ratio of the output test cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YanHui Pass rate: 0.4583333333333333\n",
      "FuzzGPT-FS Pass rate: 0.16666666666666666\n"
     ]
    }
   ],
   "source": [
    "with open(\"evaluation/yanhui_results.txt\", \"r\") as f:\n",
    "    l1 = f.readline()\n",
    "    total = int(l1.split(\":\")[-1])\n",
    "\n",
    "    test_id = None\n",
    "    fail_output = 0\n",
    "\n",
    "    for line in f.readlines():\n",
    "        if line.strip() == \"\":\n",
    "            continue\n",
    "\n",
    "        if test_id is None and line.startswith(\"#\"):\n",
    "            test_id = int(line.strip().split(\"#\")[1][:-1])\n",
    "            continue\n",
    "        if test_id is not None:\n",
    "            if line != \"pass\":\n",
    "                fail_output += 1\n",
    "            test_id = None\n",
    "\n",
    "    pass_rate = (total - fail_output) / total\n",
    "    print(f\"YanHui Pass rate: {pass_rate}\")\n",
    "\n",
    "with open(\"evaluation/random_results.txt\", \"r\") as f:\n",
    "    l1 = f.readline()\n",
    "    total = int(l1.split(\":\")[-1])\n",
    "\n",
    "    test_id = None\n",
    "    fail_output = 0\n",
    "\n",
    "    for line in f.readlines():\n",
    "        if line.strip() == \"\":\n",
    "            continue\n",
    "\n",
    "        if test_id is None and line.startswith(\"#\"):\n",
    "            test_id = int(line.strip().split(\"#\")[1][:-1])\n",
    "            continue\n",
    "        if test_id is not None:\n",
    "            if line != \"pass\":\n",
    "                fail_output += 1\n",
    "            test_id = None\n",
    "\n",
    "    pass_rate = (total - fail_output) / total\n",
    "    print(f\"FuzzGPT-FS Pass rate: {pass_rate}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
