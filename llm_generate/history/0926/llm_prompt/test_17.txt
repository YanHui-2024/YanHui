# API: TorchScript, CUDA, complex
# Bug description: Trace sanity check fails when using autocast on Conv node
#                  when using torch.jit.trace in PyTorch v1.9.1
import torch

def foo(x: torch.Tensor, y: torch.Tensor, W: torch.Tensor):
    return torch.exp(torch.mm(torch.complex(x, y), W.cfloat()))

@torch.jit.script
def jitted_foo(x: torch.Tensor, y: torch.Tensor, W: torch.Tensor):
    return torch.exp(torch.mm(torch.complex(x, y), W.cfloat()))

x = torch.randn(128, 16, dtype=torch.float32, device='cuda:0')
y = torch.randn(128, 16, dtype=torch.float32, device='cuda:0')
W = torch.randn(16, 1, dtype=torch.float32, device='cuda:0', requires_grad=True)
W.data /= 4
print('1st launch - foo(...).grad_fn is None = {}'.format(foo(x, y, W).grad_fn is None)) # outputs False, which is what's expected
print('2nd launch - foo(...).grad_fn is None = {}'.format(foo(x, y, W).grad_fn is None)) # outputs False, again as expected
print('1st launch - jitted_foo(...).grad_fn is None = {}'.format(jitted_foo(x, y, W).grad_fn is None)) # outputs False, again as expected
print('2nd launch - jitted_foo(...).grad_fn is None = {}'.format(jitted_foo(x, y, W).grad_fn is None)) # outputs True, meaning the graph is lost


# API: Fusion groups with comparison ops
# Bug description: Comparision op is mistakenly fused into the graph of previous fusion group
#                  when using torch.jit.script in PyTorch v1.0rc1
import torch

def f(x, y, z):
    return ((x + y) / z) >= z

inputs = [torch.randn(2, 2, device='cuda') for _ in range(3)]
real_output = f(*inputs)
fs = torch.jit.script(f)
output = fs(*inputs)
print(fs.graph_for(*inputs))
print(output)
print(real_output)


# API: JIT Compilation of Python 3.9
# Bug description: JIT compilation fails if running in a environment with Python-3.9
import torch
def foo(x: torch.Tensor) -> float: 
    return x[-3]
bar=torch.jit.script(foo)
print(bar(torch.rand((10,))))


# API: Python.function: math.round and torch.jit.ScriptFunction: torch.jit.script
# Bug description: round is not supported in TorchScript with the same semantics as python
import torch

def foo():    
    return round(2.5)

sfoo = torch.jit.script(foo)
print(foo(), sfoo())
# gives
# 2, 3.0


# API: