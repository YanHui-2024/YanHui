# API: TorchScript, CUDA, complex
# Bug description: Trace sanity check fails when using autocast on Conv node
#                  when using torch.jit.trace in PyTorch v1.9.1
import torch

def foo(x: torch.Tensor, y: torch.Tensor, W: torch.Tensor):
    return torch.exp(torch.mm(torch.complex(x, y), W.cfloat()))

@torch.jit.script
def jitted_foo(x: torch.Tensor, y: torch.Tensor, W: torch.Tensor):
    return torch.exp(torch.mm(torch.complex(x, y), W.cfloat()))

x = torch.randn(128, 16, dtype=torch.float32, device='cuda:0')
y = torch.randn(128, 16, dtype=torch.float32, device='cuda:0')
W = torch.randn(16, 1, dtype=torch.float32, device='cuda:0', requires_grad=True)
W.data /= 4
print('1st launch - foo(...).grad_fn is None = {}'.format(foo(x, y, W).grad_fn is None)) # outputs False, which is what's expected
print('2nd launch - foo(...).grad_fn is None = {}'.format(foo(x, y, W).grad_fn is None)) # outputs False, again as expected
print('1st launch - jitted_foo(...).grad_fn is None = {}'.format(jitted_foo(x, y, W).grad_fn is None)) # outputs False, again as expected
print('2nd launch - jitted_foo(...).grad_fn is None = {}'.format(jitted_foo(x, y, W).grad_fn is None)) # outputs True, meaning the graph is lost


# API: layerNorm
# Bug description: Error printing a model containing LayerNorm.
#                  This is a minimal script to reproduce the issue.
import torch
from torch import nn
class Test(nn.Module):
def __init__(self):
super().__init__()
self.layer_norm = nn.LayerNorm(5)
def forward(self, x):
pass
t = Test()
print(t)
import torch
from torch.nn import LayerNorm
from torch.jit import ScriptModule


class Test(ScriptModule):
    def __init__(self, dim):
        super().__init__()
        self.layer_norm = LayerNorm(dim)


if __name__ == '__main__':
    m = Test(100)
    print(m)


# API: Trace
# Bug description: a segmentation fault after calling `inlined_graph.nodes()`
#                  when using torch.jit in PyTorch v1.7.1
import torch
from torch import nn
class A(nn.Module):
    def forward(self, x):
        return x * 2
print(torch.__version__)
model = A()
trace = torch.jit.trace(model, torch.tensor([3]))
print(trace.inlined_graph)
n = trace.inlined_graph.nodes()
print(list(n))


# API: ScriptModule
# Bug description: The trace does not have model signature
#                  when using torch.jit.trace on inception v3 model
#                  in PyTorch version: 1.0.0
traced_script_module(example) # Tries to print out the model signature, but fails with exception:
import torch
import torchvision

# An instance of your model.
model = torchvision.models.inception_v3(pretrained=True)

# An example input you would normally provide to your model's forward() method.
example = torch.rand(1, 3, 299, 299)

# Use torch.jit.trace to generate a torch.jit.ScriptModule via tracing.
traced_script_module = torch.jit.trace(model, example)


# API: