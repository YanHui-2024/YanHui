{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Context preparation\n",
    "\n",
    "Infill issue information, including title, output, PR, etc., into the context.\n",
    "\n",
    "For different group, change `group` into one in the comments.\n",
    "\n",
    "The output is under the `llm_label/{group}` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import requests\n",
    "\n",
    "TOKEN = \"ghp_YOUR_TOKEN\"\n",
    "\n",
    "\n",
    "def get_pr(timeline: str):\n",
    "    timeline = requests.get(\n",
    "        timeline,\n",
    "        headers={\n",
    "            \"Accept\": \"application/vnd.github+json\",\n",
    "            \"Authorization\": f\"Bearer {TOKEN}\",\n",
    "        },\n",
    "    ).json()\n",
    "\n",
    "    for t in timeline:\n",
    "        if t[\"event\"] != \"cross-referenced\":\n",
    "            continue\n",
    "        if t[\"source\"][\"type\"] != \"issue\":\n",
    "            continue\n",
    "        issue = t[\"source\"][\"issue\"]\n",
    "        if issue[\"repository\"][\"full_name\"] != \"pytorch/pytorch\":\n",
    "            continue\n",
    "        if \"pull_request\" not in issue:\n",
    "            continue\n",
    "        return title\n",
    "\n",
    "    return \"\"\n",
    "\n",
    "\n",
    "group = \"gpu\"  # \"operator\", \"syntax\", \"typing\"\n",
    "\n",
    "group_path = os.path.join(\"grouped_code\", group)\n",
    "out_path = os.path.join(\"llm_label\", group)\n",
    "\n",
    "with open(\"full_data.json\", \"r\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "with open(\"releases.json\", \"r\") as f:\n",
    "    releases = json.load(f)\n",
    "\n",
    "for file in os.listdir(group_path):\n",
    "    if not file.endswith(\".py\"):\n",
    "        continue\n",
    "\n",
    "    number = int(file.split(\"_\")[0])\n",
    "\n",
    "    issue = None\n",
    "    for d in data:\n",
    "        if d[\"number\"] == number:\n",
    "            issue = d\n",
    "            break\n",
    "    if issue is None:\n",
    "        continue\n",
    "\n",
    "    title = issue[\"title\"]\n",
    "\n",
    "    output = \"N/A\"\n",
    "    if os.path.exists(os.path.join(group_path, f\"{number}_output.txt\")):\n",
    "        with open(os.path.join(group_path, f\"{number}_output.txt\"), \"r\") as f:\n",
    "            output = f.read()\n",
    "\n",
    "    pr_title = get_pr(issue[\"timeline_url\"])\n",
    "\n",
    "    version = None\n",
    "    if os.path.exists(os.path.join(out_path, f\"{number}_env.txt\")):\n",
    "        with open(os.path.join(out_path, f\"{number}_env.txt\"), \"r\") as f:\n",
    "            for line in f.readlines():\n",
    "                if \"PyTorch version:\" in line:\n",
    "                    version = line.strip()\n",
    "                    break\n",
    "\n",
    "    if version is None:\n",
    "        create = issue[\"created_at\"]\n",
    "        for release in releases:\n",
    "            if release[\"published_at\"] < create:\n",
    "                tag_name = release[\"tag_name\"]\n",
    "                version = f\"PyTorch version: {tag_name[1:]}\"\n",
    "                break\n",
    "\n",
    "    labels = \"\"\n",
    "    for label in issue[\"labels\"]:\n",
    "        if len(labels) > 0:\n",
    "            labels += \", \"\n",
    "        labels += f'{label[\"name\"]}'\n",
    "\n",
    "    with open(os.path.join(group_path, file), \"r\") as f:\n",
    "        code = f.read()\n",
    "\n",
    "    with open(os.path.join(out_path, f\"{number}.txt\"), \"w\") as f:\n",
    "        f.write(f\"# Title: {title}\\n\")\n",
    "        f.write(f'\"\"\"\\nOutput:\\n{output}\\n\"\"\"\\n')\n",
    "        f.write(f\"# Version: {version}\\n\")\n",
    "        f.write(f\"# Labels: {labels}\\n\")\n",
    "        f.write(f\"# PR Title: {pr_title}\\n\")\n",
    "        f.write(f\"{code}\\n\")\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text summarization\n",
    "\n",
    "LLM generation for bug description summarization.\n",
    "\n",
    "The following cell is using [llama.cpp](https://www.google.com/url?sa=t&source=web&rct=j&opi=89978449&url=https://github.com/ggerganov/llama.cpp) and CodeLLama Python 7B.\n",
    "\n",
    "For different categories, change `input_category` into one in the comments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "\n",
    "base_path = \"llm_label\"\n",
    "input_category = \"gpu\"  # \"operator\", \"syntax\", \"typing\"\n",
    "\n",
    "context = os.path.join(base_path, \"context.txt\")\n",
    "input_path = os.path.join(base_path, input_category)\n",
    "\n",
    "intermidiate_path = os.path.join(base_path, \"full_context\")\n",
    "output_path = os.path.join(base_path, \"llm_output\")\n",
    "\n",
    "with open(context, \"r\") as f:\n",
    "    context = f.read()\n",
    "\n",
    "for file in os.listdir(input_path):\n",
    "    if not file.endswith(\".txt\"):\n",
    "        continue\n",
    "\n",
    "    if os.path.exists(os.path.join(output_path, file)):\n",
    "        continue\n",
    "\n",
    "    with open(os.path.join(input_path, file), \"r\") as f:\n",
    "        snippet = f.read()\n",
    "\n",
    "    while \"\\n\\n\" in snippet:\n",
    "        snippet = snippet.replace(\"\\n\\n\", \"\\n\")\n",
    "\n",
    "    with open(os.path.join(intermidiate_path, file), \"w\") as f:\n",
    "        f.write(f\"{context}\\n{snippet}# API:\")\n",
    "\n",
    "    result = subprocess.run(\n",
    "        [\n",
    "            \"llama-cli\",\n",
    "            \"-m\",\n",
    "            \"/path/to/model\",\n",
    "            \"-c\",\n",
    "            \"16000\",\n",
    "            \"-n\",\n",
    "            \"2048\",\n",
    "            \"-ngl\",\n",
    "            \"1\",\n",
    "            \"-f\",\n",
    "            os.path.join(intermidiate_path, file),\n",
    "        ],\n",
    "        check=True,\n",
    "        capture_output=True,\n",
    "    )\n",
    "\n",
    "    with open(os.path.join(output_path, file), \"w\") as f:\n",
    "        f.write(result.stdout.decode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Format the output\n",
    "\n",
    "From the generated text in `llm_label/llm_output`, we will format the output to match the the concentation component of the final context.\n",
    "\n",
    "The formated output for each issue will be saved in `llm_label/labeld`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_path = os.path.join(\"grouped_code\", input_category)\n",
    "group = input_category\n",
    "\n",
    "summary_path = os.path.join(base_path, \"llm_output\")\n",
    "out_path = os.path.join(base_path, \"labeled\", group)\n",
    "\n",
    "for file in os.listdir(group_path):\n",
    "    if not file.endswith(\".py\"):\n",
    "        continue\n",
    "\n",
    "    number = int(file.split(\"_\")[0])\n",
    "\n",
    "    if os.path.exists(os.path.join(out_path, f\"{number}.txt\")):\n",
    "        continue\n",
    "\n",
    "    if not os.path.exists(os.path.join(summary_path, f\"{number}.txt\")):\n",
    "        continue\n",
    "\n",
    "    with open(os.path.join(group_path, file), \"r\") as f:\n",
    "        code = f.read()\n",
    "\n",
    "    with open(os.path.join(summary_path, f\"{number}.txt\"), \"r\") as f:\n",
    "        summaries = []\n",
    "        for line in f.readlines():\n",
    "            if len(line.strip()) == 0 and len(summaries) > 0:\n",
    "                break\n",
    "            if line.startswith(\"# API:\"):\n",
    "                break\n",
    "            summaries.append(line.strip())\n",
    "        summary = \"\\n\".join(summaries)\n",
    "\n",
    "    with open(os.path.join(out_path, f\"{number}.txt\"), \"w\") as f:\n",
    "        f.write(f\"# API: {summary}\\n\")\n",
    "        f.write(f\"{code}\\n\")\n",
    "        pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.1.-1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
