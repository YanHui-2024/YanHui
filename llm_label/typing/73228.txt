# Title: TorchScript not computing the correct type for complex scalar
"""
Output:
tensor(2.+6.j, device='cuda:0')
(2+6j)
graph(%x.1 : complex,
      %y.1 : Tensor):
  %6 : int = prim::Constant[value=2]() # /home/gaoxiang/misc/jit_complex_scalar.py:5:8
  %4 : complex = aten::ComplexImplicit(%y.1) # /home/gaoxiang/misc/jit_complex_scalar.py:4:8
  %o.1 : complex = aten::add(%x.1, %4) # /home/gaoxiang/misc/jit_complex_scalar.py:4:8
  %o.5 : complex = aten::add(%6, %o.1) # /home/gaoxiang/misc/jit_complex_scalar.py:5:8
  return (%o.5)

graph(%x.1 : complex,
      %y.1 : Tensor):
  %2 : int = prim::Constant[value=2]() # /home/gaoxiang/misc/jit_complex_scalar.py:5:8
  %3 : complex = aten::ComplexImplicit(%y.1) # /home/gaoxiang/misc/jit_complex_scalar.py:4:8
  %o.1 : complex = aten::add(%x.1, %3) # /home/gaoxiang/misc/jit_complex_scalar.py:4:8
  %o.5 : complex = aten::add(%2, %o.1) # /home/gaoxiang/misc/jit_complex_scalar.py:5:8
  return (%o.5)
"""
# Version: PyTorch version: 1.10.2
# Labels: oncall: jit
# PR Title: 
import torch

def f(x: complex, y: torch.Tensor):
    o = torch.add(x, y)
    o = 2 + o
    return o

jf = torch.jit.script(f)
x = 1j
y = torch.tensor(5j, device='cuda')

print(f(x, y))
print(jf(x, y))
print(jf.graph)
print(jf.graph_for(x, y))
