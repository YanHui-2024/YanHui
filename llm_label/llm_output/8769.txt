 Autograd
# Bug description: The code should be jit-able, but cannot be compiled.

# Title: [JIT] IntList arguments for call are not valid
"""
Output:
Traceback (most recent call last):
  File "test/test_jit.py", line 4396, in test_time_sequence_prediction
    self.checkTrace(Sequence(), (torch.rand(97, 999),), verbose=True)
  File "/Users/wanchaol/pytorch/torch/jit/__init__.py", line 558, in init_then_register
    self._create_methods(asts, rcbs)
RuntimeError:
arguments for call are not valid:
  for operator zeros(IntList size, int64_t dtype=<default>, IntList device=<default>, int64_t layout=<default>):
  expected a value of type Tensor for argument 'size' but found (Tensor, int)
"""
# Version: PyTorch version: 0.4.0
# Labels: oncall: jit
# PR Title: [JIT] IntList arguments for call are not valid
def test(input):
    a = torch.zeros((input.size(0), 50), dtype=torch.double)
# API: Autograd
# Bug description: The code should be jit-able, but cannot be compiled.

# Title: [JIT] Incorrectly tries to import a module for an invocation of an inlined function
"""
Output:
/tmp/jit_c1574702937885942186.py
RuntimeError: 
arguments for call are not valid:
  for operator __getitem__(Tensor self, int index):
  expected a value of type Tensor for argument 'self' but found (Tensor, int)
"""
# Version: PyTorch version: 1.5.0
# Labels: oncall: jit
# PR Title: [JIT] Incorrectly tries to import a module for an invocation of an inlined function
import torch
from torch.nn import functional as F
def test(x, y):
    z = (2 * x + 3) ** 5 - F.relu(y)
    return z
x, y = torch.randn([1, 2, 4]), torch.randn(10)
z = test(x, y)
# API: functional modules for autograd
# Bug description: The function should be jit-able, but cannot be compiled.
