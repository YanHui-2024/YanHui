 List
# Bug description: Trace sanity check fails when using autocast on Conv node
#                  when using torch.jit.trace in PyTorch v1.12.1

# Title: [JIT] Torch.jit.script(module) raises an error with custom classes and __repr__
"""
Output:
RuntimeError: Expected a value of type 'int' for return annotation, but got type 'MyClass' (while trying to infer the type of the argument 'my_inst')
        def forward(%self : __main__.MyModule, %x.1 : Tensor): #26
            %7 : int = prim::Constant[value=0]()
            return %self.my_inst.__repr__(%7)
"""
# Version: PyTorch version: 1.2.0
# Labels: oncall: jit, module: onnx
# PR Title: 
import torch
from typing import Optional
@torch.jit.script
class MyClass(object):
    def __init__(self, x: int) -> None:
        self.x = x
    def __repr__(self) -> str:
        return f"MyClass({self.x})"
def my_mod(a : Optional[int], b : MyClass):
    if a is not None:
        return f"{b}"
class MyModule(torch.nn.Module):
    def __init__(self):
        super().__init__()
        self.my_inst = MyClass(3)
    def forward(self, a : Optional[int]):
        return my_mod(a, self.my_inst)
sm = MyModule()
print(torch.jit.script(sm))
# API: Optional[int], MyClass, torch.nn.Module
# Bug description: Trace sanity check fails when using autocast on Conv node
#                  when using torch.jit.trace in PyTorch v1.12.1

# Title: [JIT] Runtime error with torch.jit.script(f(a, b) -> a+b), f(x, y) = a / b
"""
Output:
RuntimeError: expected type Double but found Float at position 0
         %17 : int[static_size=1] = prim::Constant[value=[3]]() # <--- HERE
         %18 : float[] = prim::ListConstruct(%a) # <--- HERE
         %19 : Double(eager_type=Double, static_type=Double[static_size=2]) = aten::div(%17, %b)
"""
# Version: PyTorch version: 1.3.1
# Labels: oncall: jit, module: onnx
# PR Title: [JIT] Runtime error with torch.jit.script(f(a, b) -> a+b), f(x, y) = a / b
from typing import Optional
def f(a : Optional[int], b : Optional[float]) -> float:
    if a is not None and b is not None:
        return (a/b).double()
torch.jit.script(f)
# API: torchvision.models, torch.nn.Module, Optional[int], Optional[float]
# Bug description: Trace sanity check fails when using autocast on Conv node
#                  when using torch.jit.trace in PyTorch v1.12.1

# Title: [JIT] Unsatisfiable condition after TorchScripting
"""
Output:
RuntimeError: Unsatisfiable condition at position 49
          %56 : int = prim::Constant[value=0](), # <--- HERE
          = prim::If(%57)
"""
# Version: PyTorch version: 1.3.1
# Labels: oncall: jit, module: onnx
# PR Title: [JIT] Unsatisfiable condition after TorchScripting
from torch import nn
class M(nn.Module):
    def forward(self, x):
        if x is not None and x[0] < 100:
            return x[:, :2, ...]
        else:
            return x
m = M()
print(torch.jit.trace(m, (torch.randn([3, 5, 40, 60]),)))
# API: torchvision.models, torch.nn.Module, Tuple[Tensor, ...]
# Bug description: Trace sanity check fails when using autocast on Conv node
#                  when using torch.jit.trace in PyTorch v1.12.1
