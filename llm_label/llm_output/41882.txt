 NN Module Interface
# Bug description: The cloning fails when using certain hierarchies involving module interfaces in PyTorch v1.5.1

# Title: [ONNX] RuntimeError in forward of torch.nn.MaxPool2d
"""
Output:
  ERROR: Graphs differed across invocations!
  Graph diff:
        graph(%self.3 : __torch__.torch.nn.modules.upsampling.___torch_mangle_14.Upsample,
              %input : Float(2770, 2908, 3, strides=[36, 65, 1], requires_grad=0, device=cuda:0, 
                            layout=torch._C.StridedLayout(slice(None), slice(None), []))):
          %1 : Tensor = prim::GetAttr[name="scale_factor"](%self.3)
          %2 : int = prim::Constant[value=2]()
          %3 : int = prim::Constant[value=3]()
          %4 : int = aten::floordiv(%1, %3)  # test/test_models_onnx.py:89:0
                   ~~~~~~~~~~~~~~~ <--- HERE
          %5 : Tensor = aten::ceil(%4)  # test/test_models_onnx.py:89:0
          %6 : int[] = prim::ListConstruct(%2, %3, %5)  # test/test_models_onnx.py:89:0
          %7 : Tensor[] = aten::arange(1, %6, 1, 43, False)  # test/test_models_onnx.py:89:0
          %8 : int = prim::ListUnpack(%7)
          %9 : Float = prim::Constant[value=2.5]()
          %10 : Tensor = aten::add(%input, %9, %8)  # test/test_models_onnx.py:89:0
          return (%10)
        First diverging operator:
        Node diff:
            - %5 : int = aten::ceil(%4)  # test/test_models_onnx.py:89:0
            ?                           ^
            + %5 : int = aten::ceil(%1)  # test/test_models_onnx.py:89:0
            ?                           ^
"""
# Version: PyTorch version: 1.7.1
# Labels: high priority, triage review, oncall: jit
# PR Title: [ONNX] RuntimeError in forward of torch.nn.MaxPool2d
import torch
from typing import Optional
class Model(torch.nn.Module):
    def __init__(self, upsample_scale_factor: int) -> None:
        super().__init__()
        self._upsample = torch.nn.UpsamplingNearest2d(scale_factor=upsample_scale_factor)  # type: ignore[attr-defined]
    def forward(self, inputs: torch.Tensor) -> torch.Tensor:
        return self._upsample(inputs + 2.5) * 3
if __name__ == "__main__":
    x = torch.randn((16, 3, 2770, 2908)).cuda()
    model = Model(1).cuda().eval()
    torch.onnx.export(model, (x), "test.onnx")
# API: UpsamplingNearest2d
# Bug description: RuntimeError in forward of MaxPool2d 
#                  when using the export utility in PyTorch v1.7.1

# Title: TorchScript tracing fails with custom autograd function
"""
Output:
  def forward(self, x):
        return F.softsign()(x)
RuntimeError: softsign_autograd is not a valid name for an autograd function or module (got: 'softsign_autograd')
"""
# Version: PyTorch version: 1.8.0, JIT version: 1.7.0
# Labels: high priority, triage review, oncall: jit
# PR Title: TorchScript tracing fails with custom autograd function
import torch
class Model(torch.nn.Module):
    def forward(self, x):
        return F.softsign()(x)
model = Model().cuda()
torch.jit.trace(Model(), (torch.randn((10, 2)).cuda()), check_trace=False) # JIT claims it errors here
# API: torch.nn.SoftSign
# Bug description: TorchScript tracing fails with custom autograd function in PyTorch v1.8.0

# Title: Runtime error while exporting a model containing nn.Sequential as input. 
"""
Output:
  File "exporter_test.py", line 58, in <module>
    model = Model().to(device)
  File "/home/titaiwang/.conda/envs/pytorch-1.7/lib/python3.6/site-packages/torch/nn/modules/module.py", line 305, in to
    return super(_ModuleState, self).to(device)
RuntimeError: CUDA error while calling forward pass on module 'Sequential'. RuntimeError: no element with uid <cudnn::Context> is registered!
"""
# Version: PyTorch version: 1.7.0
# Labels: high priority, triage review, oncall: jit
# PR Title: Runtime error while exporting a model containing nn.Sequential as input. 
import torch
class Model(torch.nn.Module):
    def __init__(self, device):
        super().__init__()
        self.model = torch.nn.Sequential(
            torch.nn.Linear(10, 20),
            torch.nn.ReLU(),
            torch.nn.Linear(20, 5)
        ).to(device)
    def forward(self, x):
        return self.model(x)
model = Model("cuda").eval()
torch.onnx.export(model, (torch.randn((10, 10))), "test.onnx") # JIT claims it errors here
# API: torch.nn.Sequential
# Bug description: Runtime error while exporting a model containing nn.Sequential as input. in PyTorch v1.7.0
