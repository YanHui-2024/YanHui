 tracing of RNN model in PyTorch
# Bug description: Trace sanity check fails when using traced model on GPU
#                  in PyTorch v1.0.0

# Title: torch.jit.trace not working for models that share weight (torch.nn)
"""
Output:
ERROR : Module has unused parameters.
Traceback (most recent call last):
    File "test/tinytest_models_regr.py", line 21, in <module>
        print(torch.jit.trace(model, dummy))
    File "/home/titaiwang/pytorch/torch/jit/_tracing.py", line 645, in trace
        raise RuntimeError("Module has unused parameters.")
RuntimeError: Module has unused parameters.
"""
# Version: PyTorch version: 1.2.0
# Labels: oncall: jit
# PR Title: torch.jit.trace not working for models that share weight (torch.nn)
import copy
import torch
from collections import namedtuple
from typing import Dict, NamedTuple, Optional, Tuple
class M(torch.nn.Module):
    def __init__(self):
        super().__init__()
        self.conv1 = torch.nn.Conv2d(3, 3, kernel_size=1)
        self.linear1 = torch.nn.Linear(8, 5)
    def forward(self, x: torch.Tensor):
        out = {}
        out['h0'] = x * self.conv1(x)
        return {'out': out}
dummy = torch.randn(2, 3, 8, 8)
model = M()
traced_model_cpu = torch.jit.trace(model, dummy) # works fine!
model = model.to('cuda')
traced_model_gpu = torch.jit.trace(model, dummy.to('cuda')) # error!
# API: tracing of RNN model in PyTorch
# Bug description: Trace sanity check fails when using traced model on GPU
#                  in PyTorch v1.0.0

# Title: Module has unused parameters. (torch)
"""
Output:
ERROR : Module has unused parameters.
Traceback (most recent call last):
    File "test/tinytest_models_regr.py", line 28, in <module>
        print(traced_model_gpu(dummy))
    File "/home/titaiwang/pytorch/torch/jit/_tracing.py", line 645, in trace
        raise RuntimeError("Module has unused parameters.")
RuntimeError: Module has unused parameters.
"""
# Version: PyTorch version: 1.2.0
# Labels: oncall: jit
# PR Title: Module has unused parameters. (torch)
model_cpu = Architecture()
traced_model_cpu = torch.jit.trace(model_cpu, dummy) # works fine!
dummy_gpu = dummy.to('cuda')
model_gpu = model_cpu.to('cuda')
traced_model_gpu = torch.jit.trace(model_gpu, dummy_gpu) # error!
# API: tracing of RNN model in PyTorch
# Bug description: Trace sanity check fails when using traced model on GPU
#                  in PyTorch v1.0.0

# Title: Segmentation fault(core dumped) with a jit script containing a call to a torch.nn.functional module (torch)
"""
Output:
Traceback (most recent call last):
    File "/home/titaiwang/pytorch/torch/jit/_recursive.py", line 85, in create_script_module_impl
        return create_script_module_impl(nn_module, concrete_type)
      File "/home/titaiwang/pytorch/torch/jit/_recursive.py", line 90, in create_script_module_impl
    raise RuntimeError("No method named {} was found!".format(name))
RuntimeError: No method named relu was found!
Segmentation fault (core dumped)
"""
# Version: PyTorch version: 1.2.0
# Labels: oncall: jit, module: functional_api
# PR Title: Segmentation fault(core dumped) with a jit script containing a call to a torch.nn.functional module (torch)
import copy
import torch
from collections import namedtuple
from typing import Dict, NamedTuple, Optional, Tuple
class M(torch.nn.Module):
    def __init__(self):
        super().__init__()
        self.conv1 = torch.nn.Conv2d(3, 3, kernel_size=1)
        self.linear1 = torch.nn.Linear(8, 5)
    def forward(self, x: torch.Tensor):
        return torch.relu(x * self.conv1(x))
model_cpu = M()
dummy = torch.randn(2, 3, 8, 8)
traced_model_cpu = torch.jit.trace(model_cpu, dummy) # works fine!
model_gpu = copy.deepcopy(model_cpu).to('cuda')
dummy_gpu = dummy.to('cuda')
traced_model_gpu = torch.jit.trace(model_gpu, dummy_gpu) # error!
# API: Segmentation fault in PyTorch v1.2.0
# Bug description: Trace sanity check fails when using traced model on GPU
#                  in PyTorch v1.2.0 (torch/jit/_recursive.py#L90)

# Title: Differences between torch.jit.script and torch.jit.trace
"""
Output:
        * trace_model :  __torch__.M.forward
        * script_model:  M
        * cpu_input   :  Tensor()
        * gpu_input   :  tensor([[0., 1., 2., 3., 4., 5., 6., 7.]])
        * cpu_res     :  Tensor()
        * gpu_res     :  tensor([[0., 0., 0., 0., 0.], [0., 1., 2., 3., 4.]])
"""
# Version: PyTorch version: 1.2.0
# Labels: oncall: jit, module: scripting_api, module: tracing_api
# PR Title: Differences between torch.jit.script and torch.jit.trace
import copy
import torch
from collections import namedtuple
from typing import Optional, Tuple
class M(torch.nn.Module):
    def __init__(self):
        super().__init__()
        self.conv1 = torch.nn.Conv2d(3, 64, kernel_size=7, stride=(2, 2), padding=(3, 3))
    def forward(self, x: torch.Tensor):
        return x * self.conv1(x)
m = M().eval()
traced = torch.jit.trace_module(m, {"forward": copy.deepcopy(dummy)})
scripted = torch.jit.script(m)
print("*"*20 + " trace_model " + "*"*20)
for n in dir(traced):
    print(n)
print("*"*20 + " script_model " + "*"*20)
for n in dir(scripted):
    print(n)
print("cpu_input", dummy)
print("gpu_input", dummy.to('cuda'))
print("cpu_res", traced.forward(copy.deepcopy(dummy)))
print("gpu_res", traced.forward(copy.deepcopy(dummy).to('cuda')))
# API: Differences between torch.jit.script and torch.jit.trace
# Bug description: a RuntimeError on model with custom type of NamedTuple
#                  when using torch.jit.script in PyTorch v1.2.0

# Title: Segmentation fault(core dumped) with a jit script containing a call to a torch