# Title: REGR: Accessing dict in JITed code in 1.11
"""
Output:
python test.py
Traceback (most recent call last):
  File "test.py", line 43, in <module>
    x, xs = model.forward(torch.ones(10, 10), {})
RuntimeError: The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File "test.py", line 36, in forward
            x = torch.cat((x, score), dim=1)  # removing this line makes it work
        else:
            x, meta = self.activation(x, meta)
                      ~~~~~~~~~~~~~~~ <--- HERE
        meta["meta_y_hat"] = x  # removing this line makes it work
        return meta["meta_y_hat"], meta
  File "test.py", line 13, in forward
        meta["meta_y_hat"] = x
        # return x, meta # would make it work
        return meta["meta_y_hat"], meta  # JIT claims it errors here
               ~~~~~~~~~~~~~~~~~ <--- HERE
RuntimeError: KeyError: meta_y_hat
"""
# Version: PyTorch version: 1.11.0
# Labels: oncall: jit
# PR Title: REGR: Accessing dict in JITed code in 1.11
from typing import Final
import torch
class LinearActivation(torch.nn.Module):
    def forward(
        self, x: torch.Tensor, meta: dict[str, torch.Tensor]
    ) -> tuple[torch.Tensor, dict[str, torch.Tensor]]:
        meta = meta.copy()
        meta["meta_y_hat"] = x
        # return x, meta # would make it work
        return meta["meta_y_hat"], meta  # JIT claims it errors here
class Test(torch.nn.Module):
    def __init__(self):
        super().__init__()
        self.flag: Final = ""
        self.activation = LinearActivation()
    def forward(
        self, x: torch.Tensor, meta: dict[str, torch.Tensor]
    ) -> tuple[torch.Tensor, dict[str, torch.Tensor]]:
        meta = meta.copy()
        if self.flag != "":  # this branch should not even be compiled
            # assert False # would make it work
            score = x[:, -1:]
            x, meta = self.activation(
                x[:, :, :-1],  # replacing this with x, would make it work
                meta,
            )
            x = torch.cat((x, score), dim=1)  # removing this line makes it work
        else:
            x, meta = self.activation(x, meta)
        meta["meta_y_hat"] = x  # removing this line makes it work
        return meta["meta_y_hat"], meta
if __name__ == "__main__":
    model = torch.jit.script(Test())
    x, xs = model.forward(torch.ones(10, 10), {})
# API: Dict in JIT Model
# Bug description: a KeyError on model with custom activation
#                  when accessing the property of Dict using torch.jit.script in PyTorch v1.11

# Title: Support default values on NamedTuple fields
"""
Output:
Traceback (most recent call last):
  File "test/tinytest.py", line 22, in <module>
    scripted = torch.jit.script(M())
  File "/home/ansley/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/jit/_script.py", line 947, in script
    return torch.jit._recursive.create_script_module(
  File "/home/ansley/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/jit/_recursive.py", line 398, in create_script_module
    return create_script_module_impl(nn_module, concrete_type, stubs_fn)
  File "/home/ansley/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/jit/_recursive.py", line 459, in create_script_module_impl
    create_methods_and_properties_from_stubs(concrete_type, method_stubs, property_stubs)
  File "/home/ansley/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/jit/_recursive.py", line 341, in create_methods_and_properties_from_stubs
    concrete_type._create_methods_and_properties(property_defs, property_rcbs, method_defs, method_rcbs, method_defaults)
  File "/home/ansley/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/jit/annotations.py", line 351, in try_ann_to_type
    return torch._C._resolve_type_from_object(ann, loc, fake_rcb)
RuntimeError: 
Default values are currently not supported on NamedTuple fields in TorchScript. Fields with default values: [xy]:
  File "test/tinytest.py", line 17
    def forward(self, point: Point):
                             ~~~~~ <--- HERE
        return point
"""
# Version: PyTorch version: 1.7.1
# Labels: oncall: jit
# PR Title: 
import torch
from torch.fx import symbolic_trace
from collections import namedtuple
from typing import Dict, NamedTuple, Optional, Tuple
class Point(NamedTuple):
    x: Optional[torch.Tensor] = None
    y: Optional[torch.Tensor] = None
class M(torch.nn.Module):
    def __init__(self):
        super(M, self).__init__()
    def forward(self, point: Point):
        return point
p = Point(x=torch.rand(3), y=torch.rand(3))
scripted = torch.jit.script(M())
# API: NamedTuple in JIT Model
# Bug description: a RuntimeError on model accepting a custom type of NamedTuple
#                  when using torch.jit.script in PyTorch v1.7.1

# Title: torch.jit.trace doesn't work with autocast on Conv node.
"""
Output:
ERROR: Graphs differed across invocations!
        Graph diff:
                  graph(%self.1 : __torch__.MyModule,
                        %x : Tensor):
                    %cv1 : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name="cv1"](%self.1)
                    %4 : int = prim::Constant[value=15]()
                +   %9 : Tensor = prim::Constant[value=0.01 *  6.7810  6.4636  5.3894 [ CUDAHalfType{3} ]](), scope: __module.cv1 # /home/titaiwang/pytorch/torch/nn/modules/conv.py:459:0
                +   %10 : Tensor = prim::Constant[value=<Tensor>](), scope: __module.cv1 # /home/titaiwang/pytorch/torch/nn/modules/conv.py:459:0
                ?             ^
                +   return (%22)
                ?             ^
        First diverging operator:
        Node diff:
                - %cv1 : __torch__.torch.nn.modules.conv.___torch_mangle_2.Conv2d = prim::GetAttr[name="cv1"](%self.1)
                ?                                                        ^
                + %cv1 : __torch__.torch.nn.modules.conv.___torch_mangle_4.Conv2d = prim::GetAttr[name="cv1"](%self.1)
                ?                                                        ^
"""
# Version: PyTorch version: 1.12.1
# Labels: oncall: jit, module: onnx, module: amp (automated mixed precision), onnx-triaged
# PR Title: torch.jit.trace doesn't work with autocast on Conv node.
import torch

class MyModule(torch.nn.Module):
    def __init__(self):
        super().__init__()
        self.cv1 = torch.nn.Conv2d(3, 3, 5, 2, 1)

    def forward(self, x):
        x = self.cv1(x)
        return x

x = torch.randn(10, 3, 20, 20) * 2
m = MyModule().eval()
x = x.cuda()
m = m.cuda()

with torch.no_grad():
    print("outside result: ", torch.jit.trace(m, x))
    with torch.cuda.amp.autocast(enabled = True, dtype=torch.float16):
        print("inside result: ", torch.jit.trace(m, x))
# API: torch.nn.Conv2d
# Bug description: Trace sanity check fails when using autocast on Conv node
#                  when using torch.jit.trace in PyTorch v1.12.1

# Title: RuntimeError: input_values.size() == param_count_list.size()INTERNAL ASSERT FAILED at "..\\torch\\csrc\\jit\\python\\script_init.cpp":480
"""
Output:
N/A
"""
# Version: PyTorch version: 1.10.2
# Labels: oncall: jit, module: onnx
# PR Title: RuntimeError: input_values.size() == param_count_list.size()INTERNAL ASSERT FAILED at "..\\torch\\csrc\\jit\\python\\script_init.cpp":480
from nets.models import DigitModel
import torch
import os
import onnx
#load pretrained torch model
def load_model(model, pretrained_path, load_to_cpu):
    print('Loading pretrained model from {}'.format(pretrained_path))
    if load_to_cpu:
        pretrained_dict = torch.load(pretrained_path, map_location=lambda storage, loc: storage)
    else:
        device = torch.cuda.current_device()
        pretrained_dict = torch.load(pretrained_path, map_location=lambda storage, loc: storage.cuda(device))
    model.load_state_dict(pretrained_dict, strict=False)
    return model
#convert to onnx model
def pth_to_onnx(model,input_path, output_path):
    
    torch_model = load_model(model,input_path,True)  
    torch_model.eval()
    torch_model = torch.jit.script(torch_model)
    x=torch.randn(1,1,28,28, device="cuda")
    export_onnx_file = output_path  
    print(torch_model)
    # Note: the bug is here
    torch.onnx.export(torch_model,
                      x,
                      export_onnx_file,
                      verbose=True,
                      opset_version=9,  
                      do_constant_folding=True, 
                      input_names=["input"], 
                      output_names=["output"] ,
                      dynamic_axes={"input": {0: "batch_size"}, 
                                     "output": {0: "batch_size"}}
                      )
#DigitModel 
#@inproceedings{
#  anonymous2022unsupervised,
#  title={Unsupervised Federated Learning is Possible},
#  author={Anonymous},
#  booktitle={Submitted to The Tenth International Conference on Learning Representations},
#  year={2022},
#  url={https://openreview.net/forum?id=WHA8009laxu},
#  note={under review}
# }
import torch
import torch.nn as nn
import torch.nn.functional as func
import torchvision
class DigitModel(nn.Module):
    def __init__(self, class_num=10):
        super(DigitModel, self).__init__()
        self.class_num = class_num
        self.conv1 = nn.Conv2d(3, 64, 5, 1, 2)
        self.bn1 = nn.BatchNorm2d(64)
        self.conv2 = nn.Conv2d(64, 64, 5, 1, 2)
        self.bn2 = nn.BatchNorm2d(64)
        self.conv3 = nn.Conv2d(64, 128, 5, 1, 2)
        self.bn3 = nn.BatchNorm2d(128)
        self.fc1 = nn.Linear(6272, 2048)
        self.bn4 = nn.BatchNorm1d(2048)
        self.fc2 = nn.Linear(2048, 512)
        self.bn5 = nn.BatchNorm1d(512)
        self.fc3 = nn.Linear(512, class_num)
    def forward(self, x, Pi, priors_corr, prior_test):
        x = func.relu(self.bn1(self.conv1(x)))
        x = func.max_pool2d(x, 2)
        x = func.relu(self.bn2(self.conv2(x)))
        x = func.max_pool2d(x, 2)
        x = func.relu(self.bn3(self.conv3(x)))
        x = x.view(x.shape[0], -1)
        x = self.fc1(x)
        x = self.bn4(x)
        x = func.relu(x)
        x = self.fc2(x)
        x = self.bn5(x)
        x = func.relu(x)
        x = self.fc3(x)
        g = torch.softmax(x, dim=1)
        x = self.QfunctionMulticlass(g, Pi, priors_corr)
        return x
    def QfunctionMulticlass(self, g, Pi, priors_corr):
        pi_ita = torch.mm(Pi, g.permute(1, 0))
        rou_pi_ita = torch.matmul(priors_corr, pi_ita)
        pi_corr = pi_ita.permute(1, 0) * priors_corr.unsqueeze(0)
        output = (pi_corr.permute(1, 0) / rou_pi_ita).permute(1, 0)
        return output
    def predict(self, x):
        x = func.relu(self.bn1(self.conv1(x)))
        x = func.max_pool2d(x, 2)
        x = func.relu(self.bn2(self.conv2(x)))
        x = func.max_pool2d(x, 2)
        x = func.relu(self.bn3(self.conv3(x)))
        x = x.view(x.shape[0], -1)
        x = self.fc1(x)
        x = self.bn4(x)
        x = func.relu(x)
        x = self.fc2(x)
        x = self.bn5(x)
        x = func.relu(x)
        x = self.fc3(x)
        g = torch.softmax(x, dim=1)
        return g
#trackback
Traceback (most recent call last):
  File "D:/BaiduNetdiskDownload/FedUL/load_model.py", line 119, in <module>
    pth_to_onnx(model,input_path, onnx_path) 
  File "D:/BaiduNetdiskDownload/FedUL/load_model.py", line 35, in pth_to_onnx
    torch.onnx.export(torch_model,
  File "C:\tools\Anaconda3\envs\fedul\lib\site-packages\torch\onnx\__init__.py", line 316, in export
    return utils.export(model, args, f, export_params, verbose, training,
  File "C:\tools\Anaconda3\envs\fedul\lib\site-packages\torch\onnx\utils.py", line 107, in export
    _export(model, args, f, export_params, verbose, training, input_names, output_names,
  File "C:\tools\Anaconda3\envs\fedul\lib\site-packages\torch\onnx\utils.py", line 724, in _export
    _model_to_graph(model, args, verbose, input_names,
  File "C:\tools\Anaconda3\envs\fedul\lib\site-packages\torch\onnx\utils.py", line 493, in _model_to_graph
    graph, params, torch_out, module = _create_jit_graph(model, args)
  File "C:\tools\Anaconda3\envs\fedul\lib\site-packages\torch\onnx\utils.py", line 422, in _create_jit_graph
    graph = _propagate_and_assign_input_shapes(
RuntimeError: input_values.size() == param_count_list.size()INTERNAL ASSERT FAILED at "..\\torch\\csrc\\jit\\python\\script_init.cpp":480, please report a bug to PyTorch. 
Process finished with exit code 1
# API: